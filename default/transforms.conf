######### lookups
# the job that is running on each node 
[job]
filename = job.csv.gz
time_field = time
time_format = %m/%d/%Y:%H:%M:%S

[cray]
filename = cray.csv

# the last job that started on each node (the above, minus job end records)
[jobstart]
filename = jobstart.csv.gz
time_field = time
time_format = %m/%d/%Y:%H:%M:%S

# longer range version of the above
[job-archive]
filename = job-archive.csv.gz
time_field = time
time_format = %m/%d/%Y:%H:%M:%S

# longer range version of the above
[jobstart-archive]
filename = jobstart-archive.csv.gz
time_field = time
time_format = %m/%d/%Y:%H:%M:%S

[cos]
filename = cos.csv.gz
time_field = time
time_format = %s

[group]
filename = group.csv

[genders]
filename = genders.csv

[ib]
filename = ib.csv

[links]
filename = links.csv

[hosts]
filename = hosts.csv

[users]
filename = users.csv

######### other stuff
[sdrhost]
DEST_KEY = MetaData:Host
REGEX = \S+ \S+ (\S+):
FORMAT = host::$1

[mv-symbol_error-port]
MV_ADD = true
REGEX= (?mi)port (?<port>\d+): \[SymbolErrorCounter == (?P<SymbolErrors>\d+)(?=\])

[mv-port]
MV_ADD = true
REGEX= port (\d+):
FORMAT = port::$1

[mv-symbol_errors]
MV_ADD = true
REGEX = \d+: \[SymbolErrorCounter == (\d+)\]
FORMAT = SymbolErrors::$1

# hostoverride, src, and errors might be consolidated into a "hostfirst" rule:
# REGEX = ^([a-zA-Z]\S+):*
[src]
DEST_KEY = MetaData:Host
REGEX = ^(\S+)
FORMAT = host::$1

[hostisthird]
DEST_KEY = MetaData:Host
REGEX = ^\d\d\d\d-\d\d-\d\d \d\d:\d\d:\d\d (\S+)
FORMAT = host::$1

[hostlist]
external_cmd = hostlistLookup.py short long
fields_list = short, long

# use this if you want to use the state lookup instead of getstate search
#[stateLookup]
#external_cmd = state.py node eventtype state
#fields_list = node, eventtype, state, _time
#time_field = _time

[crayhost]
DEST_KEY = MetaData:Host
REGEX = src:[^| ]+:([-csn0-9]+)\|
FORMAT = host::$1
